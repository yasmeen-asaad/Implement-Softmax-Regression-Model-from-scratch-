{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b0b7bd0",
   "metadata": {},
   "source": [
    "Implement and train Softmax Regression with mini-batch SGD and early stopping.\n",
    "\n",
    "The expected outcome.\n",
    "* Implement Softmax Regression Model.\n",
    "* Implement mini-batch SGD.\n",
    "* The training should support early stopping.\n",
    "* Train and evaluate the model with cross-validation. The evaluation metric is the *accuracy*.\n",
    "* Retrain the model with early stopping.\n",
    "\n",
    "\n",
    "**DO NOT USE SKLEARN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c066137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f4f1598e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"]\n",
    "y = iris[\"target\"]\n",
    "df = pd.DataFrame({fname: values for fname, values in zip(iris[\"feature_names\"], X.T)})\n",
    "df[\"target\"] = y\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c595d",
   "metadata": {},
   "source": [
    "## Your Code\n",
    "You can start writing your code from here. Please don't modify any of the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5620a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mini_batches(X, y, n):\n",
    "    '''\n",
    "    X: matrix of features values of the training set\n",
    "    y: vector of targe feature \n",
    "    n: number of batches\n",
    "    '''\n",
    "    return np.array_split(X, n), np.array_split(y, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f7cc194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(vect):\n",
    "    '''vect:the vectore to encode'''\n",
    "    \n",
    "    # Get categories  \n",
    "    cats = np.unique(vect)\n",
    "    \n",
    "    # Creaty empty array (n, k)\n",
    "    n = vect.shape[0]\n",
    "    k = cats.shape[0]\n",
    "    new_matrix = np.empty((n, k))\n",
    "    \n",
    "    for c in cats :\n",
    "        new_matrix[:, c] = [1 if i == c else 0 for i in vect]\n",
    "        \n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "3d06df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftMax(S):\n",
    "    ''' S: Score Matrix'''\n",
    "    # Number of observations\n",
    "    n = S.shape[0]\n",
    "    \n",
    "    # predict: vector contains the index with heigher probability\n",
    "    # Initalize predict array\n",
    "    predict = np.empty(n)\n",
    "    \n",
    "    # Initalize probabilty array\n",
    "    probabilities = np.empty(S.shape)\n",
    "    \n",
    "    # Index refers to class that contain higher probabilty\n",
    "    # Foreach vector(1,3) in S, save the index with heigher probability in predict \n",
    "    \n",
    "    for i in range(n):\n",
    "        v_exponentials = np.exp(S[i, :])\n",
    "        probabilities[i] = v_exponentials / np.sum(v_exponentials)\n",
    "        predict[i] = np.argmax(probabilities[i])\n",
    "        \n",
    "    return predict, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "1509ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(prop, Y):\n",
    "    '''\n",
    "    cross_entropy = -1/m * summation yk * log(pk)\n",
    "    prop: Probability Matrix\n",
    "    Y: Matrix of onehot encoded Y, each column represent class and it's value one only for the instence who \n",
    "       belongg to that class\n",
    "    '''\n",
    "    # Number of classes \n",
    "    k = Y.shape[1]\n",
    "    \n",
    "    # Number of observations \n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # Calculate log of probabilities Matrix\n",
    "    log_prop = np.log(prop)\n",
    "    \n",
    "    sum = 0\n",
    "    for i in range(k):\n",
    "        sum += Y[:, i].dot(log_prop[:, i])\n",
    "        \n",
    "    return -1 * (sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "315dc71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softmax_Gradient_Descent(X_data, y_data, batch, alpha=0.05, threshold = 0.2, max_iter=5000):\n",
    "    '''\n",
    "   # X_data (n, m+1): Feature Matrix\n",
    "                     n observations \n",
    "                     m features +1 for bias\n",
    "    \n",
    "   # Y_data (n, k): Target Vector \"y_data\" adjust to be matrix \n",
    "                   n observations\n",
    "                   k class labels\n",
    "    \n",
    "   # batch:\n",
    "       - 1                     = Vanilla GD\n",
    "       - data_size(m)          = Stochastic GD\n",
    "       - number of batches(n)  = Mini Batch GD    \n",
    "       \n",
    "   # alpha: Learning Rate\n",
    "   \n",
    "   # threshold: if Cost Function near to the minmum \"threshold\" so BREAK, else update theats\n",
    "   \n",
    "   # max_iter: number of iteration over all data\n",
    "                -------------------------------------------------------------\n",
    "                \n",
    "    W (m, k): Weight Matrix\n",
    "              m features\n",
    "              k class labels\n",
    "    \n",
    "    Z(n+1, k): Logit Score Matrix\n",
    "               n observations, +1 for bias\n",
    "               k class labels\n",
    "    '''\n",
    "    n = X_data.shape[0]\n",
    "    m = X_data.shape[1]\n",
    "    k = np.unique(y_data).shape[0]\n",
    "       \n",
    "    # Add ones column in the beggining of X matrix for bias  \n",
    "    # X_data are (n,m+1)\n",
    "    ones = np.ones(n)\n",
    "    X_data = np.column_stack((ones, X_data))\n",
    "    \n",
    "    # Adjust y vector to be Y matrix \n",
    "    Y_data = one_hot_encoder(y_data)\n",
    "\n",
    "    # Initakize Weight matrix W(m, k)\n",
    "    #W = np.zeros((m+1, k))\n",
    "    W = np.random.random((m+1, k))\n",
    "    \n",
    "    # divid X and y to batches\n",
    "    X_batches, y_batches = create_mini_batches(X_data, Y_data, batch)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        # Iterate over batches \n",
    "        for j in range(batch):\n",
    "            \n",
    "            X = X_batches[j]\n",
    "            Y = y_batches[j]\n",
    "            \n",
    "            # Calculate Score Matrix/ logits S\n",
    "            S = X.dot(W)\n",
    "            \n",
    "            # Predict outbut\n",
    "            predict, class_probabilties  = SoftMax(S)\n",
    "            \n",
    "            # Calculate the cost function/ loss cross entropy cost function\n",
    "            loss = cross_entropy(class_probabilties, Y)\n",
    "\n",
    "            # Check if Cost Function near to the minmum \"threshold\" so BREAK, else update Weight \n",
    "            if loss <= threshold:\n",
    "                break\n",
    "                \n",
    "            # Calculate the Gradient of Theta\n",
    "            # number of data \n",
    "            # Update Weight matrix \n",
    "            # Update weight foreach class \n",
    "            for c in range(k):\n",
    "                p = class_probabilties[:, c]\n",
    "                y = Y[:, c]\n",
    "                term = p - y \n",
    "                b = X.shape[0]\n",
    "                \n",
    "                # Calculate gredient \n",
    "                delta = 1/b * (term.dot(X))\n",
    "        \n",
    "                # Update weigth\n",
    "                W[:, c] = W[:, c] - (alpha * delta)\n",
    "            \n",
    "        if loss <= threshold:\n",
    "            break\n",
    "    # Return Weight values, Cost function \n",
    "    predicts, class_probabilties = SoftMax(X_data.dot(W))\n",
    "    return W, predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "990a6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, p):\n",
    "    '''\n",
    "    y: Actual vector\n",
    "    p: Predict vector\n",
    "    '''\n",
    "    # True Positive tp\n",
    "    tp = 0\n",
    "    all = y.shape[0]\n",
    "    for i in range(all):\n",
    "        if p[i] == y[i]:\n",
    "            tp += 1\n",
    "    \n",
    "    return tp / all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb4956",
   "metadata": {},
   "source": [
    "Using the following cell to train and evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "626be344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "The accuray of the the train is 0.975\n",
      "The accuray of the the test is 0.9666666666666667\n",
      "---------------------------\n",
      "Fold  2\n",
      "The accuray of the the train is 0.9916666666666667\n",
      "The accuray of the the test is 0.9\n",
      "---------------------------\n",
      "Fold  3\n",
      "The accuray of the the train is 0.9833333333333333\n",
      "The accuray of the the test is 0.9\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "indx = 0\n",
    "for train_index, test_index in split.split(df, df[\"target\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "    \n",
    "    # Use strat_train_set and strat_test_set to train and evaluate your mode\n",
    "    indx += 1\n",
    "    print(\"Fold \", indx)\n",
    "    X_train = strat_train_set.iloc[:, :-1].to_numpy()\n",
    "    y_train = strat_train_set.iloc[:, -1].to_numpy()\n",
    "    \n",
    "    Weight, train_predicts = Softmax_Gradient_Descent(X_train, y_train, batch=3, alpha=0.05, threshold = 0.2, max_iter=500)\n",
    "    \n",
    "    acc = accuracy(y_train, train_predicts)\n",
    "    print(\"The accuray of the the train is {0}\".format(acc))\n",
    "    \n",
    "    X_test = strat_test_set.iloc[:, :-1].to_numpy()\n",
    "    n = X_test.shape[0]\n",
    "    ones = np.ones(n)\n",
    "    X_test = np.column_stack((ones, X_test))\n",
    "    y_test = strat_test_set.iloc[:, -1].to_numpy()\n",
    "    \n",
    "    test_predicts, probabilities = SoftMax(X_test.dot(Weight))\n",
    "    \n",
    "    acc2 = accuracy(y_test, test_predicts)\n",
    "    print(\"The accuray of the the test is {0}\".format(acc2))\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "2333211e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
